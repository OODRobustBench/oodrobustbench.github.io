<table id="imagenet_leaderboard_Linf" class="datatable" style="width: 100%">
    <thead>
    <tr>
        <th class="rank">Rank</th>
        <th class="method">Method</th>
        <th class="ca">
            Standard<br/>
            accuracy
        </th>
        
        <th class="aa">
            AutoAttack<br/>
            robust<br/>
            accuracy
        </th>
        <th class="aa-ext">
            Best known<br/>
            robust<br/>
            accuracy
        </th>
        <th class="aa-ext">
            AA eval.<br/>
            potentially<br/>
            unreliable
        </th>
        
        
        
        <th class="extra-data">Extra <br/>data</th>
        <th class="arch">Architecture</th>
        <th class="venue">Venue</th>
    </tr>
    </thead>
    <tbody>
    
<tr><td class="ranktd">1</td><td class="methoddt"><a href="https://arxiv.org/abs/2302.14301" target="_blank">A Comprehensive Study on Robustness of Image Classification Models: Benchmarking and Rethinking</a></td><td class="idcatd">78.92%</td><td class="idratd">59.82%</td><td class="oodratd">26.74%</td><td class="ooddcatd">45.84%</td><td class="ooddratd">23.59%</td><td class="oodtratd">29.88%</td><td class="datatd">&#215;</td><td class="archtd">Swin-L</td><td class="venuetd">arXiv, Feb 2023</td></tr>
<tr><td class="ranktd">2</td><td class="methoddt"><a href="https://arxiv.org/abs/2302.14301" target="_blank">A Comprehensive Study on Robustness of Image Classification Models: Benchmarking and Rethinking</a></td><td class="idcatd">78.02%</td><td class="idratd">58.76%</td><td class="oodratd">26.72%</td><td class="ooddcatd">44.74%</td><td class="ooddratd">23.35%</td><td class="oodtratd">30.10%</td><td class="datatd">&#215;</td><td class="archtd">ConvNeXt-L</td><td class="venuetd">arXiv, Feb 2023</td></tr>
<tr><td class="ranktd">3</td><td class="methoddt"><a href="https://arxiv.org/abs/2303.01870" target="_blank">Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models</a></td><td class="idcatd">77.00%</td><td class="idratd">57.82%</td><td class="oodratd">25.53%</td><td class="ooddcatd">44.05%</td><td class="ooddratd">23.09%</td><td class="oodtratd">27.98%</td><td class="datatd">&#215;</td><td class="archtd">ConvNeXt-L + ConvStem</td><td class="venuetd">NeurIPS 2023</td></tr>
<tr><td class="ranktd">4</td><td class="methoddt"><a href="https://arxiv.org/abs/2303.01870" target="_blank">Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models</a></td><td class="idcatd">76.30%</td><td class="idratd">54.90%</td><td class="oodratd">25.37%</td><td class="ooddcatd">44.67%</td><td class="ooddratd">21.76%</td><td class="oodtratd">28.98%</td><td class="datatd">&#215;</td><td class="archtd">ViT-B + ConvStem</td><td class="venuetd">NeurIPS 2023</td></tr>
<tr><td class="ranktd">5</td><td class="methoddt"><a href="https://arxiv.org/abs/2303.01870" target="_blank">Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models</a></td><td class="idcatd">75.88%</td><td class="idratd">56.24%</td><td class="oodratd">24.83%</td><td class="ooddcatd">42.29%</td><td class="ooddratd">21.77%</td><td class="oodtratd">27.89%</td><td class="datatd">&#215;</td><td class="archtd">ConvNeXt-B + ConvStem</td><td class="venuetd">NeurIPS 2023</td></tr>
<tr><td class="ranktd">6</td><td class="methoddt"><a href="https://arxiv.org/abs/2302.14301" target="_blank">A Comprehensive Study on Robustness of Image Classification Models: Benchmarking and Rethinking</a></td><td class="idcatd">76.70%</td><td class="idratd">56.02%</td><td class="oodratd">24.36%</td><td class="ooddcatd">43.06%</td><td class="ooddratd">21.74%</td><td class="oodtratd">26.97%</td><td class="datatd">&#215;</td><td class="archtd">ConvNeXt-B</td><td class="venuetd">arXiv, Feb 2023</td></tr>
<tr><td class="ranktd">7</td><td class="methoddt"><a href="https://arxiv.org/abs/2302.14301" target="_blank">A Comprehensive Study on Robustness of Image Classification Models: Benchmarking and Rethinking</a></td><td class="idcatd">76.16%</td><td class="idratd">56.26%</td><td class="oodratd">24.24%</td><td class="ooddcatd">42.58%</td><td class="ooddratd">21.45%</td><td class="oodtratd">27.02%</td><td class="datatd">&#215;</td><td class="archtd">Swin-B</td><td class="venuetd">arXiv, Feb 2023</td></tr>
<tr><td class="ranktd">8</td><td class="methoddt"><a href="https://arxiv.org/abs/2303.01870" target="_blank">Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models</a></td><td class="idcatd">74.08%</td><td class="idratd">52.66%</td><td class="oodratd">23.11%</td><td class="ooddcatd">39.55%</td><td class="ooddratd">19.35%</td><td class="oodtratd">26.87%</td><td class="datatd">&#215;</td><td class="archtd">ConvNeXt-S + ConvStem</td><td class="venuetd">NeurIPS 2023</td></tr>
<tr><td class="ranktd">9</td><td class="methoddt"><a href="https://arxiv.org/abs/2303.01870" target="_blank">Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models</a></td><td class="idcatd">72.70%</td><td class="idratd">49.46%</td><td class="oodratd">21.65%</td><td class="ooddcatd">38.15%</td><td class="ooddratd">17.97%</td><td class="oodtratd">25.32%</td><td class="datatd">&#215;</td><td class="archtd">ConvNeXt-T + ConvStem</td><td class="venuetd">NeurIPS 2023</td></tr>
<tr><td class="ranktd">10</td><td class="methoddt"><a href="https://arxiv.org/abs/2303.01870" target="_blank">Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models</a></td><td class="idcatd">72.58%</td><td class="idratd">48.46%</td><td class="oodratd">21.63%</td><td class="ooddcatd">39.24%</td><td class="ooddratd">17.83%</td><td class="oodtratd">25.43%</td><td class="datatd">&#215;</td><td class="archtd">ViT-S + ConvStem</td><td class="venuetd">NeurIPS 2023</td></tr>
<tr><td class="ranktd">11</td><td class="methoddt"><a href="https://arxiv.org/abs/2209.07399" target="_blank">A Light Recipe to Train Robust Vision Transformers</a></td><td class="idcatd">73.78%</td><td class="idratd">47.88%</td><td class="oodratd">19.53%</td><td class="ooddcatd">38.10%</td><td class="ooddratd">15.84%</td><td class="oodtratd">23.22%</td><td class="datatd">&#215;</td><td class="archtd">XCiT-L12</td><td class="venuetd">arXiv, Sep 2022</td></tr>
<tr><td class="ranktd">12</td><td class="methoddt"><a href="https://arxiv.org/abs/2209.07399" target="_blank">A Light Recipe to Train Robust Vision Transformers</a></td><td class="idcatd">74.04%</td><td class="idratd">45.76%</td><td class="oodratd">18.77%</td><td class="ooddcatd">37.00%</td><td class="ooddratd">14.73%</td><td class="oodtratd">22.82%</td><td class="datatd">&#215;</td><td class="archtd">XCiT-M12</td><td class="venuetd">arXiv, Sep 2022</td></tr>
<tr><td class="ranktd">13</td><td class="methoddt"><a href="https://arxiv.org/abs/2209.07399" target="_blank">A Light Recipe to Train Robust Vision Transformers</a></td><td class="idcatd">72.34%</td><td class="idratd">42.18%</td><td class="oodratd">17.03%</td><td class="ooddcatd">35.68%</td><td class="ooddratd">12.72%</td><td class="oodtratd">21.35%</td><td class="datatd">&#215;</td><td class="archtd">XCiT-S12</td><td class="venuetd">arXiv, Sep 2022</td></tr>
<tr><td class="ranktd">14</td><td class="methoddt"><a href="https://arxiv.org/abs/2007.08489" target="_blank">Do Adversarially Robust ImageNet Models Transfer Better?</a></td><td class="idcatd">68.64%</td><td class="idratd">38.52%</td><td class="oodratd">13.81%</td><td class="ooddcatd">31.09%</td><td class="ooddratd">11.73%</td><td class="oodtratd">15.88%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-50-2</td><td class="venuetd">NeurIPS 2020</td></tr>
<tr><td class="ranktd">15</td><td class="methoddt"><a href="https://arxiv.org/abs/2007.08489" target="_blank">Do Adversarially Robust ImageNet Models Transfer Better?</a></td><td class="idcatd">64.06%</td><td class="idratd">35.02%</td><td class="oodratd">12.48%</td><td class="ooddcatd">28.05%</td><td class="ooddratd">11.01%</td><td class="oodtratd">13.96%</td><td class="datatd">&#215;</td><td class="archtd">ResNet-50</td><td class="venuetd">NeurIPS 2020</td></tr>
<tr><td class="ranktd">16</td><td class="methoddt"><a href="https://github.com/MadryLab/robustness" target="_blank">Robustness library</a></td><td class="idcatd">62.52%</td><td class="idratd">29.84%</td><td class="oodratd">11.28%</td><td class="ooddcatd">27.73%</td><td class="ooddratd">8.96%</td><td class="oodtratd">13.60%</td><td class="datatd">&#215;</td><td class="archtd">ResNet-50</td><td class="venuetd">GitHub,<br>Oct 2019</td></tr>
<tr><td class="ranktd">17</td><td class="methoddt"><a href="https://arxiv.org/abs/2001.03994" target="_blank">Fast is better than free: Revisiting adversarial training</a><br><span class="td-footer">Focuses on fast adversarial training.</span></td><td class="idcatd">55.64%</td><td class="idratd">26.84%</td><td class="oodratd">9.66%</td><td class="ooddcatd">21.90%</td><td class="ooddratd">7.70%</td><td class="oodtratd">11.61%</td><td class="datatd">&#215;</td><td class="archtd">ResNet-50</td><td class="venuetd">ICLR 2020</td></tr>
<tr><td class="ranktd">18</td><td class="methoddt"><a href="https://arxiv.org/abs/2007.08489" target="_blank">Do Adversarially Robust ImageNet Models Transfer Better?</a></td><td class="idcatd">52.92%</td><td class="idratd">25.50%</td><td class="oodratd">9.15%</td><td class="ooddcatd">21.79%</td><td class="ooddratd">7.87%</td><td class="oodtratd">10.42%</td><td class="datatd">&#215;</td><td class="archtd">ResNet-18</td><td class="venuetd">NeurIPS 2020</td></tr>

      
    </tbody>
</table>
<script>
    $(document).ready(function () {
        $("#imagenet_leaderboard_Linf").DataTable({
            lengthMenu: [15, 25, 50, 75, 100],
            "drawCallback": function (settings) {
                MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
            },
            language: {
                searchPlaceholder: "Papers, architectures, venues"
            },
            
            columnDefs: [
                { width: "15%", targets: 4 },
                { width: "15%", targets: 5 }
            ]
            
        });
    });
</script>

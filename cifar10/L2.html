<table id="cifar10_leaderboard_L2" class="datatable" style="width: 100%">
    <thead>
    <tr>
        <th class="rank">Rank</th>
        <th class="method">Method</th>
        <th class="idca">
            ID<br/>
            clean<br/>
            acc.
        </th>
        
        <th class="idra">
            ID<br/>
            robust<br/>
            acc.
        </th>
	<th class="oodra">
            OOD<br/>
            robust<br/>
            acc.
        </th>
        <th class="ooddca">
            OOD-D<br/>
            clean<br/>
            acc.
        </th>
        <th class="ooddra">
            OOD-D<br/>
            robust<br/>
            acc.
        </th>
        <th class="oodtra">
            OOD-T<br/>
            robust<br/>
            acc.
        </th>
        
        
        <th class="extra-data">Extra <br/>data</th>
        <th class="arch">Arch.</th>
        <th class="venue">Venue</th>
    </tr>
    </thead>
    <tbody>
    
<tr><td class="ranktd">1</td><td class="methoddt"><a href="https://arxiv.org/abs/2302.04638" target="_blank">Better Diffusion Models Further Improve Adversarial Training</a><br><span class="td-footer">It uses additional 50M synthetic images in training.</span></td><td class="idcatd">95.54%</td><td class="idratd">84.97%</td><td class="oodratd">48.74%</td><td class="ooddcatd">80.04%</td><td class="ooddratd">60.83%</td><td class="oodtratd">36.65%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-70-16</td><td class="venuetd">ICML 2023</td></tr>
<tr><td class="ranktd">2</td><td class="methoddt"><a href="https://arxiv.org/abs/2302.04638" target="_blank">Better Diffusion Models Further Improve Adversarial Training</a><br><span class="td-footer">It uses additional 50M synthetic images in training.</span></td><td class="idcatd">95.16%</td><td class="idratd">83.69%</td><td class="oodratd">47.21%</td><td class="ooddcatd">79.28%</td><td class="ooddratd">59.39%</td><td class="oodtratd">35.04%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">ICML 2023</td></tr>
<tr><td class="ranktd">3</td><td class="methoddt"><a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a><br><span class="td-footer">It uses additional 1M synthetic images in training.</span></td><td class="idcatd">92.41%</td><td class="idratd">80.42%</td><td class="oodratd">45.70%</td><td class="ooddcatd">75.95%</td><td class="ooddratd">56.82%</td><td class="oodtratd">34.58%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-70-16</td><td class="venuetd">arXiv, Mar 2021</td></tr>
<tr><td class="ranktd">4</td><td class="methoddt"><a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a></td><td class="idcatd">95.74%</td><td class="idratd">82.36%</td><td class="oodratd">44.82%</td><td class="ooddcatd">79.90%</td><td class="ooddratd">57.94%</td><td class="oodtratd">31.71%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-70-16</td><td class="venuetd">arXiv, Mar 2021</td></tr>
<tr><td class="ranktd">5</td><td class="methoddt"><a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a><br><span class="td-footer">It uses additional 1M synthetic images in training.</span></td><td class="idcatd">91.79%</td><td class="idratd">78.79%</td><td class="oodratd">44.48%</td><td class="ooddcatd">75.26%</td><td class="ooddratd">55.63%</td><td class="oodtratd">33.32%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">arXiv, Mar 2021</td></tr>
<tr><td class="ranktd">6</td><td class="methoddt"><a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a></td><td class="idcatd">94.74%</td><td class="idratd">80.56%</td><td class="oodratd">43.33%</td><td class="ooddcatd">78.78%</td><td class="ooddratd">56.18%</td><td class="oodtratd">30.47%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-70-16</td><td class="venuetd">arXiv, Oct 2020</td></tr>
<tr><td class="ranktd">7</td><td class="methoddt"><a href="https://arxiv.org/abs/2003.09461" target="_blank">Adversarial Robustness on In- and Out-Distribution Improves Explainability</a></td><td class="idcatd">93.97%</td><td class="idratd">78.81%</td><td class="oodratd">43.16%</td><td class="ooddcatd">77.40%</td><td class="ooddratd">54.71%</td><td class="oodtratd">31.62%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">ECCV 2020</td></tr>
<tr><td class="ranktd">8</td><td class="methoddt"><a href="https://arxiv.org/abs/2104.09425" target="_blank">Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?</a><br><span class="td-footer">It uses additional 10M synthetic images in training.</span></td><td class="idcatd">90.93%</td><td class="idratd">77.29%</td><td class="oodratd">41.88%</td><td class="ooddcatd">74.00%</td><td class="ooddratd">54.33%</td><td class="oodtratd">29.43%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">ICLR 2022</td></tr>
<tr><td class="ranktd">9</td><td class="methoddt"><a href="https://openreview.net/forum?id=BuD2LmNaU3a" target="_blank">Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off</a><br><span class="td-footer">It uses additional 1M synthetic images in training.</span></td><td class="idcatd">90.57%</td><td class="idratd">76.14%</td><td class="oodratd">41.52%</td><td class="ooddcatd">73.55%</td><td class="ooddratd">53.35%</td><td class="oodtratd">29.69%</td><td class="datatd">&#215;</td><td class="archtd">PreActResNet-18</td><td class="venuetd">OpenReview, Jun 2021</td></tr>
<tr><td class="ranktd">10</td><td class="methoddt"><a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a><br><span class="td-footer">It uses additional 1M synthetic images in training.</span></td><td class="idcatd">90.33%</td><td class="idratd">75.87%</td><td class="oodratd">41.14%</td><td class="ooddcatd">72.96%</td><td class="ooddratd">52.21%</td><td class="oodtratd">30.06%</td><td class="datatd">&#215;</td><td class="archtd">PreActResNet-18</td><td class="venuetd">arXiv, Mar 2021</td></tr>
<tr><td class="ranktd">11</td><td class="methoddt"><a href="https://arxiv.org/abs/2003.09461" target="_blank">Adversarial Robustness on In- and Out-Distribution Improves Explainability</a><br><span class="td-footer">Extra data used only as OOD dataset.</span></td><td class="idcatd">92.23%</td><td class="idratd">76.27%</td><td class="oodratd">41.04%</td><td class="ooddcatd">76.43%</td><td class="ooddratd">52.83%</td><td class="oodtratd">29.25%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">ECCV 2020</td></tr>
<tr><td class="ranktd">12</td><td class="methoddt"><a href="https://arxiv.org/abs/2004.05884" target="_blank">Adversarial Weight Perturbation Helps Robust Generalization</a></td><td class="idcatd">88.51%</td><td class="idratd">73.66%</td><td class="oodratd">39.52%</td><td class="ooddcatd">71.23%</td><td class="ooddratd">51.53%</td><td class="oodtratd">27.50%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">NeurIPS 2020</td></tr>
<tr><td class="ranktd">13</td><td class="methoddt"><a href="https://arxiv.org/abs/2104.09425" target="_blank">Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?</a><br><span class="td-footer">It uses additional 10M synthetic images in training.</span></td><td class="idcatd">89.76%</td><td class="idratd">74.42%</td><td class="oodratd">39.22%</td><td class="ooddcatd">72.31%</td><td class="ooddratd">51.76%</td><td class="oodtratd">26.68%</td><td class="datatd">&#215;</td><td class="archtd">ResNet-18</td><td class="venuetd">ICLR 2022</td></tr>
<tr><td class="ranktd">14</td><td class="methoddt"><a href="https://arxiv.org/abs/2003.09461" target="_blank">Adversarial Robustness on In- and Out-Distribution Improves Explainability</a><br><span class="td-footer">Extra data used only as OOD dataset.</span></td><td class="idcatd">91.07%</td><td class="idratd">72.99%</td><td class="oodratd">39.02%</td><td class="ooddcatd">74.24%</td><td class="ooddratd">49.32%</td><td class="oodtratd">28.72%</td><td class="datatd">&#9745;</td><td class="archtd">ResNet-50</td><td class="venuetd">ECCV 2020</td></tr>
<tr><td class="ranktd">15</td><td class="methoddt"><a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a></td><td class="idcatd">90.89%</td><td class="idratd">74.51%</td><td class="oodratd">38.98%</td><td class="ooddcatd">74.71%</td><td class="ooddratd">52.20%</td><td class="oodtratd">25.76%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-70-16</td><td class="venuetd">arXiv, Oct 2020</td></tr>
<tr><td class="ranktd">16</td><td class="methoddt"><a href="https://github.com/MadryLab/robustness" target="_blank">Robustness library</a></td><td class="idcatd">90.83%</td><td class="idratd">69.25%</td><td class="oodratd">32.18%</td><td class="ooddcatd">73.85%</td><td class="ooddratd">46.65%</td><td class="oodtratd">17.71%</td><td class="datatd">&#215;</td><td class="archtd">ResNet-50</td><td class="venuetd">GitHub,<br>Sep 2019</td></tr>
<tr><td class="ranktd">17</td><td class="methoddt"><a href="https://arxiv.org/abs/2002.11569" target="_blank">Overfitting in adversarially robust deep learning</a></td><td class="idcatd">88.67%</td><td class="idratd">67.69%</td><td class="oodratd">31.67%</td><td class="ooddcatd">71.27%</td><td class="ooddratd">44.76%</td><td class="oodtratd">18.58%</td><td class="datatd">&#215;</td><td class="archtd">PreActResNet-18</td><td class="venuetd">ICML 2020</td></tr>
<tr><td class="ranktd">18</td><td class="methoddt"><a href="https://arxiv.org/abs/1811.09600" target="_blank">Decoupling Direction and Norm for Efficient Gradient-Based L2 Adversarial Attacks and Defenses</a></td><td class="idcatd">89.04%</td><td class="idratd">66.46%</td><td class="oodratd">31.42%</td><td class="ooddcatd">71.77%</td><td class="ooddratd">44.54%</td><td class="oodtratd">18.30%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">CVPR 2019</td></tr>    
    </tbody>
</table>
<script>
    $(document).ready(function () {
        $("#cifar10_leaderboard_L2").DataTable({
            lengthMenu: [15, 25, 50, 75, 100],
            "drawCallback": function (settings) {
                MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
            },
            language: {
                searchPlaceholder: "Papers, architectures, venues"
            },
            
            columnDefs: [
                { width: "15%", targets: 4 },
                { width: "15%", targets: 5 }
            ]
            
        });
    });
</script>

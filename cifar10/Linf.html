<table id="cifar10_leaderboard_Linf" class="datatable" style="width: 100%">
    <thead>
    <tr>
        <th class="rank">Rank</th>
        <th class="method">Method</th>
        <th class="idca">
            ID<br/>
            clean<br/>
            acc.
        </th>
        
        <th class="idra">
            ID<br/>
            robust<br/>
            acc.
        </th>
	<th class="oodra">
            OOD<br/>
            clean<br/>
            acc.
        </th>
        <th class="ooddca">
            OOD-D<br/>
            clean<br/>
            acc.
        </th>
        <th class="ooddra">
            OOD-D<br/>
            robust<br/>
            acc.
        </th>
        <th class="oodtra">
            OOD-T<br/>
            robust<br/>
            acc.
        </th>
        
        
        <th class="extra-data">Extra <br/>data</th>
        <th class="arch">Arch.</th>
        <th class="venue">Venue</th>
    </tr>
    </thead>
    <tbody>

<tr><td class="ranktd">1</td><td class="methoddt"><a href="https://arxiv.org/abs/2301.12554" target="_blank">Improving the Accuracy-Robustness Trade-off of Classifiers via Adaptive Smoothing</a><br><span class="td-footer">It uses an ensemble of networks. The robust base classifier uses 50M synthetic images.</span></td><td class="idcatd">95.23%</td><td class="idratd">69.50%</td><td class="ooddcatd">79.09%</td><td class="ooddratd">43.32%</td><td class="oodtratd">46.71%</td><td class="oodratd">45.01%</td><td class="datatd">&#9745;</td><td class="archtd">ResNet-152 + WideResNet-70-16 + mixing network</td><td class="venuetd">SIMODS 2024</td></tr>
<tr><td class="ranktd">2</td><td class="methoddt"><a href="https://arxiv.org/abs/2302.04638" target="_blank">Better Diffusion Models Further Improve Adversarial Training</a><br><span class="td-footer">It uses additional 50M synthetic images in training.</span></td><td class="idcatd">93.25%</td><td class="idratd">70.76%</td><td class="ooddcatd">76.04%</td><td class="ooddratd">44.49%</td><td class="oodtratd">35.80%</td><td class="oodratd">40.14%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-70-16</td><td class="venuetd">ICML 2023</td></tr>
<tr><td class="ranktd">3</td><td class="methoddt"><a href="https://arxiv.org/abs/2002.08619" target="_blank">Boosting Adversarial Training with Hypersphere Embedding</a></td><td class="idcatd">85.14%</td><td class="idratd">53.84%</td><td class="ooddcatd">66.96%</td><td class="ooddratd">32.45%</td><td class="oodtratd">46.20%</td><td class="oodratd">39.33%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-20</td><td class="venuetd">NeurIPS 2020</td></tr>
<tr><td class="ranktd">4</td><td class="methoddt"><a href="https://arxiv.org/abs/2305.13948" target="_blank">Decoupled Kullback-Leibler Divergence Loss</a><br><span class="td-footer">It uses additional 20M synthetic images in training.</span></td><td class="idcatd">92.16%</td><td class="idratd">67.77%</td><td class="ooddcatd">74.88%</td><td class="ooddratd">42.48%</td><td class="oodtratd">35.48%</td><td class="oodratd">38.98%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">arXiv, May 2023</td></tr>
<tr><td class="ranktd">5</td><td class="methoddt"><a href="https://arxiv.org/abs/2302.04638" target="_blank">Better Diffusion Models Further Improve Adversarial Training</a><br><span class="td-footer">It uses additional 20M synthetic images in training.</span></td><td class="idcatd">92.44%</td><td class="idratd">67.34%</td><td class="ooddcatd">75.04%</td><td class="ooddratd">42.34%</td><td class="oodtratd">35.26%</td><td class="oodratd">38.80%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">ICML 2023</td></tr>
<tr><td class="ranktd">6</td><td class="methoddt"><a href="https://arxiv.org/abs/2302.03015" target="_blank">Exploring and Exploiting Decision Boundary Dynamics for Adversarial Robustness</a><br><span class="td-footer">It uses additional 10M synthetic images in training.</span></td><td class="idcatd">93.69%</td><td class="idratd">65.20%</td><td class="ooddcatd">77.22%</td><td class="ooddratd">40.05%</td><td class="oodtratd">37.34%</td><td class="oodratd">38.70%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">ICLR 2023</td></tr>
<tr><td class="ranktd">7</td><td class="methoddt"><a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a><br><span class="td-footer">65.87% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)</span></td><td class="idcatd">91.10%</td><td class="idratd">66.03%</td><td class="ooddcatd">73.24%</td><td class="ooddratd">42.58%</td><td class="oodtratd">34.00%</td><td class="oodratd">38.29%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-70-16</td><td class="venuetd">arXiv, Oct 2020</td></tr>
<tr><td class="ranktd">8</td><td class="methoddt"><a href="https://arxiv.org/abs/2110.09468" target="_blank">Improving Robustness using Generated Data</a><br><span class="td-footer">It uses additional 100M synthetic images in training. 66.10% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)</span></td><td class="idcatd">88.74%</td><td class="idratd">66.24%</td><td class="ooddcatd">70.68%</td><td class="ooddratd">42.76%</td><td class="oodtratd">33.65%</td><td class="oodratd">38.20%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-70-16</td><td class="venuetd">NeurIPS 2021</td></tr>
<tr><td class="ranktd">9</td><td class="methoddt"><a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a><br><span class="td-footer">66.56% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)</span></td><td class="idcatd">92.23%</td><td class="idratd">66.79%</td><td class="ooddcatd">74.89%</td><td class="ooddratd">42.60%</td><td class="oodtratd">33.65%</td><td class="oodratd">38.12%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-70-16</td><td class="venuetd">arXiv, Mar 2021</td></tr>
<tr><td class="ranktd">10</td><td class="methoddt"><a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a><br><span class="td-footer">It uses additional 1M synthetic images in training. 64.58% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)</span></td><td class="idcatd">88.50%</td><td class="idratd">64.82%</td><td class="ooddcatd">70.65%</td><td class="ooddratd">41.43%</td><td class="oodtratd">33.90%</td><td class="oodratd">37.66%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-106-16</td><td class="venuetd">arXiv, Mar 2021</td></tr>
<tr><td class="ranktd">11</td><td class="methoddt"><a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a><br><span class="td-footer">It uses additional 1M synthetic images in training. 64.20% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)</span></td><td class="idcatd">88.54%</td><td class="idratd">64.33%</td><td class="ooddcatd">70.62%</td><td class="ooddratd">41.01%</td><td class="oodtratd">34.12%</td><td class="oodratd">37.56%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-70-16</td><td class="venuetd">arXiv, Mar 2021</td></tr>
<tr><td class="ranktd">12</td><td class="methoddt"><a href="https://arxiv.org/abs/2212.11005" target="_blank">Revisiting Residual Networks for Adversarial Robustness: An Architectural Perspective</a></td><td class="idcatd">91.58%</td><td class="idratd">65.87%</td><td class="ooddcatd">73.89%</td><td class="ooddratd">41.70%</td><td class="oodtratd">33.34%</td><td class="oodratd">37.52%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-A4</td><td class="venuetd">arXiv, Dec. 2022</td></tr>
<tr><td class="ranktd">13</td><td class="methoddt"><a href="https://arxiv.org/abs/2106.02078" target="_blank">Improving Neural Network Robustness via Persistency of Excitation</a></td><td class="idcatd">86.53%</td><td class="idratd">60.55%</td><td class="ooddcatd">68.19%</td><td class="ooddratd">38.80%</td><td class="oodtratd">35.37%</td><td class="oodratd">37.09%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-34-15</td><td class="venuetd">ACC 2022</td></tr>
<tr><td class="ranktd">14</td><td class="methoddt"><a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a><br><span class="td-footer">62.76% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)</span></td><td class="idcatd">89.48%</td><td class="idratd">62.89%</td><td class="ooddcatd">71.52%</td><td class="ooddratd">40.33%</td><td class="oodtratd">33.62%</td><td class="oodratd">36.98%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">arXiv, Oct 2020</td></tr>
<tr><td class="ranktd">15</td><td class="methoddt"><a href="https://arxiv.org/abs/2104.09425" target="_blank">Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?</a><br><span class="td-footer">It uses additional 10M synthetic images in training.</span></td><td class="idcatd">87.21%</td><td class="idratd">62.72%</td><td class="ooddcatd">69.20%</td><td class="ooddratd">40.77%</td><td class="oodtratd">32.35%</td><td class="oodratd">36.56%</td><td class="datatd">&#215;</td><td class="archtd">ResNest152</td><td class="venuetd">ICLR 2022</td></tr>
<tr><td class="ranktd">16</td><td class="methoddt"><a href="https://arxiv.org/abs/2110.09468" target="_blank">Improving Robustness using Generated Data</a><br><span class="td-footer">It uses additional 100M synthetic images in training. 63.38% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)</span></td><td class="idcatd">87.50%</td><td class="idratd">63.58%</td><td class="ooddcatd">69.37%</td><td class="ooddratd">40.47%</td><td class="oodtratd">31.81%</td><td class="oodratd">36.14%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">NeurIPS 2021</td></tr>
<tr><td class="ranktd">17</td><td class="methoddt"><a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a><br><span class="td-footer">It uses additional 1M synthetic images in training. 60.73% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)</span></td><td class="idcatd">87.33%</td><td class="idratd">60.88%</td><td class="ooddcatd">69.35%</td><td class="ooddratd">38.54%</td><td class="oodtratd">33.63%</td><td class="oodratd">36.09%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">arXiv, Mar 2021</td></tr>
<tr><td class="ranktd">18</td><td class="methoddt"><a href="https://arxiv.org/pdf/2202.10103.pdf" target="_blank"> Robustness and Accuracy Could Be Reconcilable by (Proper) Definition</a><br><span class="td-footer">It uses additional 1M synthetic images in training.</span></td><td class="idcatd">89.01%</td><td class="idratd">63.36%</td><td class="ooddcatd">70.99%</td><td class="ooddratd">39.77%</td><td class="oodtratd">32.34%</td><td class="oodratd">36.06%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-70-16</td><td class="venuetd">ICML 2022</td></tr>
<tr><td class="ranktd">19</td><td class="methoddt"><a href="https://arxiv.org/abs/2110.05626" target="_blank">Parameterizing Activation Functions for Adversarial Robustness</a><br><span class="td-footer">It uses additional ~6M synthetic images in training.</span></td><td class="idcatd">87.02%</td><td class="idratd">61.71%</td><td class="ooddcatd">68.93%</td><td class="ooddratd">39.22%</td><td class="oodtratd">32.32%</td><td class="oodratd">35.77%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-28-10-PSSiLU</td><td class="venuetd">arXiv, Oct 2021</td></tr>
<tr><td class="ranktd">20</td><td class="methoddt"><a href="https://arxiv.org/abs/2110.03825" target="_blank">Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks</a><br><span class="td-footer">Uses exponential moving average (EMA)</span></td><td class="idcatd">91.23%</td><td class="idratd">62.81%</td><td class="ooddcatd">73.58%</td><td class="ooddratd">39.37%</td><td class="oodtratd">32.07%</td><td class="oodratd">35.72%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-34-R</td><td class="venuetd">NeurIPS 2021</td></tr>
<tr><td class="ranktd">21</td><td class="methoddt"><a href="https://arxiv.org/abs/2104.09425" target="_blank">Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?</a><br><span class="td-footer">It uses additional 10M synthetic images in training.</span></td><td class="idcatd">86.68%</td><td class="idratd">60.47%</td><td class="ooddcatd">68.50%</td><td class="ooddratd">38.98%</td><td class="oodtratd">31.77%</td><td class="oodratd">35.38%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">ICLR 2022</td></tr>
<tr><td class="ranktd">22</td><td class="methoddt"><a href="https://openreview.net/forum?id=BuD2LmNaU3a" target="_blank">Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off</a></td><td class="idcatd">91.47%</td><td class="idratd">62.83%</td><td class="ooddcatd">73.84%</td><td class="ooddratd">39.28%</td><td class="oodtratd">31.32%</td><td class="oodratd">35.30%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">OpenReview, Jun 2021</td></tr>
<tr><td class="ranktd">23</td><td class="methoddt"><a href="https://arxiv.org/pdf/2202.10103.pdf" target="_blank"> Robustness and Accuracy Could Be Reconcilable by (Proper) Definition</a><br><span class="td-footer">It uses additional 1M synthetic images in training.</span></td><td class="idcatd">88.61%</td><td class="idratd">61.04%</td><td class="ooddcatd">70.57%</td><td class="ooddratd">38.32%</td><td class="oodtratd">32.16%</td><td class="oodratd">35.24%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">ICML 2022</td></tr>
<tr><td class="ranktd">24</td><td class="methoddt"><a href="https://arxiv.org/abs/2210.09852" target="_blank">Scaling Adversarial Training to Large Perturbation Bounds</a></td><td class="idcatd">85.32%</td><td class="idratd">58.12%</td><td class="ooddcatd">68.04%</td><td class="ooddratd">36.89%</td><td class="oodtratd">32.95%</td><td class="oodratd">34.92%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">ECCV 2022</td></tr>
<tr><td class="ranktd">25</td><td class="methoddt"><a href="https://arxiv.org/abs/2010.01736" target="_blank">Geometry-aware Instance-reweighted Adversarial Training</a><br><span class="td-footer">Uses \(\ell_{\infty} \) = 0.031 ≈ 7.9/255 instead of 8/255.</span></td><td class="idcatd">89.36%</td><td class="idratd">59.36%</td><td class="ooddcatd">70.60%</td><td class="ooddratd">36.30%</td><td class="oodtratd">33.45%</td><td class="oodratd">34.87%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">ICLR 2021</td></tr>
<tr><td class="ranktd">26</td><td class="methoddt"><a href="https://arxiv.org/abs/2004.05884" target="_blank">Adversarial Weight Perturbation Helps Robust Generalization</a></td><td class="idcatd">88.25%</td><td class="idratd">60.14%</td><td class="ooddcatd">69.82%</td><td class="ooddratd">38.20%</td><td class="oodtratd">31.39%</td><td class="oodratd">34.80%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">NeurIPS 2020</td></tr>
<tr><td class="ranktd">27</td><td class="methoddt"><a href="https://arxiv.org/abs/2110.03825" target="_blank">Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks</a></td><td class="idcatd">90.56%</td><td class="idratd">62.04%</td><td class="ooddcatd">72.64%</td><td class="ooddratd">38.38%</td><td class="oodtratd">31.18%</td><td class="oodratd">34.78%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-34-R</td><td class="venuetd">NeurIPS 2021</td></tr>
<tr><td class="ranktd">28</td><td class="methoddt"><a href="https://arxiv.org/abs/2111.02331" target="_blank">LTD: Low Temperature Distillation for Robust Adversarial Training</a></td><td class="idcatd">86.03%</td><td class="idratd">57.79%</td><td class="ooddcatd">67.33%</td><td class="ooddratd">36.32%</td><td class="oodtratd">33.17%</td><td class="oodratd">34.74%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-20</td><td class="venuetd">arXiv, Nov 2021</td></tr>
<tr><td class="ranktd">29</td><td class="methoddt"><a href="https://arxiv.org/abs/2106.02078" target="_blank">Improving Neural Network Robustness via Persistency of Excitation</a></td><td class="idcatd">89.47%</td><td class="idratd">59.81%</td><td class="ooddcatd">71.29%</td><td class="ooddratd">37.15%</td><td class="oodtratd">31.31%</td><td class="oodratd">34.23%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">ACC 2022</td></tr>
<tr><td class="ranktd">30</td><td class="methoddt"><a href="https://arxiv.org/abs/2210.15318" target="_blank">Efficient and Effective Augmentation Strategy for Adversarial Training</a></td><td class="idcatd">88.70%</td><td class="idratd">57.94%</td><td class="ooddcatd">71.01%</td><td class="ooddratd">35.59%</td><td class="oodtratd">32.63%</td><td class="oodratd">34.11%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">NeurIPS 2022</td></tr>
<tr><td class="ranktd">31</td><td class="methoddt"><a href="https://openreview.net/forum?id=rklOg6EFwS" target="_blank">Improving Adversarial Robustness Requires Revisiting Misclassified Examples</a></td><td class="idcatd">87.50%</td><td class="idratd">56.75%</td><td class="ooddcatd">70.23%</td><td class="ooddratd">35.50%</td><td class="oodtratd">32.68%</td><td class="oodratd">34.09%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">ICLR 2020</td></tr>
<tr><td class="ranktd">32</td><td class="methoddt"><a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a><br><span class="td-footer">It uses additional 1M synthetic images in training.</span></td><td class="idcatd">83.53%</td><td class="idratd">56.71%</td><td class="ooddcatd">65.51%</td><td class="ooddratd">36.24%</td><td class="oodtratd">31.90%</td><td class="oodratd">34.07%</td><td class="datatd">&#215;</td><td class="archtd">PreActResNet-18</td><td class="venuetd">arXiv, Mar 2021</td></tr>
<tr><td class="ranktd">33</td><td class="methoddt"><a href="https://arxiv.org/abs/2111.02331" target="_blank">LTD: Low Temperature Distillation for Robust Adversarial Training</a></td><td class="idcatd">85.21%</td><td class="idratd">56.99%</td><td class="ooddcatd">66.48%</td><td class="ooddratd">35.88%</td><td class="oodtratd">32.09%</td><td class="oodratd">33.99%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">arXiv, Nov 2021</td></tr>
<tr><td class="ranktd">34</td><td class="methoddt"><a href="https://arxiv.org/abs/1905.13736" target="_blank">Unlabeled Data Improves Adversarial Robustness</a></td><td class="idcatd">89.69%</td><td class="idratd">59.80%</td><td class="ooddcatd">71.57%</td><td class="ooddratd">36.74%</td><td class="oodtratd">31.12%</td><td class="oodratd">33.93%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">NeurIPS 2019</td></tr>
<tr><td class="ranktd">35</td><td class="methoddt"><a href="https://arxiv.org/abs/2305.13948" target="_blank">Decoupled Kullback-Leibler Divergence Loss</a></td><td class="idcatd">85.31%</td><td class="idratd">57.22%</td><td class="ooddcatd">66.96%</td><td class="ooddratd">35.53%</td><td class="oodtratd">31.89%</td><td class="oodratd">33.71%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">arXiv, May 2023</td></tr>
<tr><td class="ranktd">36</td><td class="methoddt"><a href="https://arxiv.org/abs/2003.12862" target="_blank">Adversarial Robustness: From Self-Supervised Pre-Training to Fine-Tuning</a><br><span class="td-footer">Uses ensembles of 3 models.</span></td><td class="idcatd">86.04%</td><td class="idratd">51.63%</td><td class="ooddcatd">67.60%</td><td class="ooddratd">31.62%</td><td class="oodtratd">35.77%</td><td class="oodratd">33.70%</td><td class="datatd">&#215;</td><td class="archtd">ResNet-50</td><td class="venuetd">CVPR 2020</td></tr>
<tr><td class="ranktd">37</td><td class="methoddt"><a href="https://arxiv.org/abs/2209.07399" target="_blank">A Light Recipe to Train Robust Vision Transformers</a></td><td class="idcatd">91.30%</td><td class="idratd">57.43%</td><td class="ooddcatd">74.08%</td><td class="ooddratd">34.15%</td><td class="oodtratd">33.03%</td><td class="oodratd">33.59%</td><td class="datatd">&#9745;</td><td class="archtd">XCiT-M12</td><td class="venuetd">arXiv, Sep 2022</td></tr>
<tr><td class="ranktd">38</td><td class="methoddt"><a href="https://arxiv.org/abs/2203.06616" target="_blank">LAS-AT: Adversarial Training with Learnable Attack Strategy</a></td><td class="idcatd">85.66%</td><td class="idratd">57.74%</td><td class="ooddcatd">67.01%</td><td class="ooddratd">36.07%</td><td class="oodtratd">30.88%</td><td class="oodratd">33.47%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-70-16</td><td class="venuetd">arXiv, Mar 2022</td></tr>
<tr><td class="ranktd">39</td><td class="methoddt"><a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a><br><span class="td-footer">56.82% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)</span></td><td class="idcatd">85.64%</td><td class="idratd">56.90%</td><td class="ooddcatd">68.01%</td><td class="ooddratd">36.11%</td><td class="oodtratd">30.61%</td><td class="oodratd">33.36%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-20</td><td class="venuetd">arXiv, Oct 2020</td></tr>
<tr><td class="ranktd">40</td><td class="methoddt"><a href="https://arxiv.org/abs/2209.07399" target="_blank">A Light Recipe to Train Robust Vision Transformers</a></td><td class="idcatd">91.73%</td><td class="idratd">57.85%</td><td class="ooddcatd">74.79%</td><td class="ooddratd">34.66%</td><td class="oodtratd">32.05%</td><td class="oodratd">33.36%</td><td class="datatd">&#9745;</td><td class="archtd">XCiT-L12</td><td class="venuetd">arXiv, Sep 2022</td></tr>
<tr><td class="ranktd">41</td><td class="methoddt"><a href="https://openreview.net/forum?id=BuD2LmNaU3a" target="_blank">Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off</a><br><span class="td-footer">It uses additional 1M synthetic images in training.</span></td><td class="idcatd">86.86%</td><td class="idratd">57.11%</td><td class="ooddcatd">68.33%</td><td class="ooddratd">35.35%</td><td class="oodtratd">31.04%</td><td class="oodratd">33.20%</td><td class="datatd">&#215;</td><td class="archtd">PreActResNet-18</td><td class="venuetd">OpenReview, Jun 2021</td></tr>
<tr><td class="ranktd">42</td><td class="methoddt"><a href="https://arxiv.org/abs/2110.09468" target="_blank">Improving Robustness using Generated Data</a><br><span class="td-footer">It uses additional 100M synthetic images in training. 58.50% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)</span></td><td class="idcatd">87.35%</td><td class="idratd">58.67%</td><td class="ooddcatd">68.87%</td><td class="ooddratd">36.36%</td><td class="oodtratd">29.88%</td><td class="oodratd">33.12%</td><td class="datatd">&#215;</td><td class="archtd">PreActResNet-18</td><td class="venuetd">NeurIPS 2021</td></tr>
<tr><td class="ranktd">43</td><td class="methoddt"><a href="https://openreview.net/forum?id=BuD2LmNaU3a" target="_blank">Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off</a></td><td class="idcatd">89.02%</td><td class="idratd">57.65%</td><td class="ooddcatd">70.70%</td><td class="ooddratd">35.61%</td><td class="oodtratd">30.47%</td><td class="oodratd">33.04%</td><td class="datatd">&#9745;</td><td class="archtd">PreActResNet-18</td><td class="venuetd">OpenReview, Jun 2021</td></tr>
<tr><td class="ranktd">44</td><td class="methoddt"><a href="https://arxiv.org/abs/2002.10509" target="_blank">HYDRA: Pruning Adversarially Robust Neural Networks</a><br><span class="td-footer">Compressed model</span></td><td class="idcatd">88.98%</td><td class="idratd">57.41%</td><td class="ooddcatd">70.79%</td><td class="ooddratd">35.40%</td><td class="oodtratd">30.64%</td><td class="oodratd">33.02%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">NeurIPS 2020</td></tr>
<tr><td class="ranktd">45</td><td class="methoddt"><a href="https://arxiv.org/abs/2203.06616" target="_blank">LAS-AT: Adversarial Training with Learnable Attack Strategy</a></td><td class="idcatd">84.98%</td><td class="idratd">56.40%</td><td class="ooddcatd">66.45%</td><td class="ooddratd">35.17%</td><td class="oodtratd">30.29%</td><td class="oodratd">32.73%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">arXiv, Mar 2022</td></tr>
<tr><td class="ranktd">46</td><td class="methoddt"><a href="https://arxiv.org/abs/2104.09425" target="_blank">Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?</a><br><span class="td-footer">It uses additional 10M synthetic images in training.</span></td><td class="idcatd">84.59%</td><td class="idratd">55.72%</td><td class="ooddcatd">66.79%</td><td class="ooddratd">35.15%</td><td class="oodtratd">30.17%</td><td class="oodratd">32.66%</td><td class="datatd">&#215;</td><td class="archtd">ResNet-18</td><td class="venuetd">ICLR 2022</td></tr>
<tr><td class="ranktd">47</td><td class="methoddt"><a href="https://arxiv.org/abs/2209.07399" target="_blank">A Light Recipe to Train Robust Vision Transformers</a></td><td class="idcatd">90.06%</td><td class="idratd">56.28%</td><td class="ooddcatd">72.68%</td><td class="ooddratd">33.76%</td><td class="oodtratd">31.55%</td><td class="oodratd">32.66%</td><td class="datatd">&#9745;</td><td class="archtd">XCiT-S12</td><td class="venuetd">arXiv, Sep 2022</td></tr>
<tr><td class="ranktd">48</td><td class="methoddt"><a href="https://openreview.net/forum?id=BuD2LmNaU3a" target="_blank">Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off</a><br><span class="td-footer">It uses additional 1M synthetic images in training.</span></td><td class="idcatd">88.16%</td><td class="idratd">60.98%</td><td class="ooddcatd">69.45%</td><td class="ooddratd">35.10%</td><td class="oodtratd">30.20%</td><td class="oodratd">32.65%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">OpenReview, Jun 2021</td></tr>
<tr><td class="ranktd">49</td><td class="methoddt"><a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a><br><span class="td-footer">57.14% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)</span></td><td class="idcatd">85.29%</td><td class="idratd">57.24%</td><td class="ooddcatd">66.98%</td><td class="ooddratd">35.90%</td><td class="oodtratd">29.39%</td><td class="oodratd">32.64%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-70-16</td><td class="venuetd">arXiv, Oct 2020</td></tr>
<tr><td class="ranktd">50</td><td class="methoddt"><a href="https://arxiv.org/abs/2002.11242" target="_blank">Attacks Which Do Not Kill Training Make Adversarial Learning Stronger</a></td><td class="idcatd">84.52%</td><td class="idratd">53.65%</td><td class="ooddcatd">65.94%</td><td class="ooddratd">32.95%</td><td class="oodtratd">31.84%</td><td class="oodratd">32.40%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">ICML 2020</td></tr>
<tr><td class="ranktd">51</td><td class="methoddt"><a href="https://arxiv.org/abs/2004.05884" target="_blank">Adversarial Weight Perturbation Helps Robust Generalization</a></td><td class="idcatd">85.35%</td><td class="idratd">56.35%</td><td class="ooddcatd">66.63%</td><td class="ooddratd">34.57%</td><td class="oodtratd">29.72%</td><td class="oodratd">32.15%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">NeurIPS 2020</td></tr>
<tr><td class="ranktd">52</td><td class="methoddt"><a href="https://arxiv.org/abs/2210.09852" target="_blank">Scaling Adversarial Training to Large Perturbation Bounds</a></td><td class="idcatd">80.24%</td><td class="idratd">51.19%</td><td class="ooddcatd">62.07%</td><td class="ooddratd">32.51%</td><td class="oodtratd">30.81%</td><td class="oodratd">31.66%</td><td class="datatd">&#215;</td><td class="archtd">ResNet-18</td><td class="venuetd">ECCV 2022</td></tr>
<tr><td class="ranktd">53</td><td class="methoddt"><a href="https://arxiv.org/abs/2210.15318" target="_blank">Efficient and Effective Augmentation Strategy for Adversarial Training</a></td><td class="idcatd">85.71%</td><td class="idratd">52.60%</td><td class="ooddcatd">67.62%</td><td class="ooddratd">32.37%</td><td class="oodtratd">30.48%</td><td class="oodratd">31.43%</td><td class="datatd">&#215;</td><td class="archtd">ResNet-18</td><td class="venuetd">NeurIPS 2022</td></tr>
<tr><td class="ranktd">54</td><td class="methoddt"><a href="https://arxiv.org/abs/1901.09960" target="_blank">Using Pre-Training Can Improve Model Robustness and Uncertainty</a></td><td class="idcatd">87.11%</td><td class="idratd">55.09%</td><td class="ooddcatd">68.94%</td><td class="ooddratd">34.30%</td><td class="oodtratd">28.21%</td><td class="oodratd">31.26%</td><td class="datatd">&#9745;</td><td class="archtd">WideResNet-28-10</td><td class="venuetd">ICML 2019</td></tr>
<tr><td class="ranktd">55</td><td class="methoddt"><a href="https://arxiv.org/abs/2002.10319" target="_blank">Self-Adaptive Training: beyond Empirical Risk Minimization</a><br><span class="td-footer">Uses \(\ell_{\infty} \) = 0.031 ≈ 7.9/255 instead of 8/255.</span></td><td class="idcatd">83.48%</td><td class="idratd">52.96%</td><td class="ooddcatd">64.90%</td><td class="ooddratd">32.22%</td><td class="oodtratd">29.87%</td><td class="oodratd">31.04%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">NeurIPS 2020</td></tr>
<tr><td class="ranktd">56</td><td class="methoddt"><a href="https://arxiv.org/abs/2002.11569" target="_blank">Overfitting in adversarially robust deep learning</a></td><td class="idcatd">85.34%</td><td class="idratd">53.52%</td><td class="ooddcatd">66.46%</td><td class="ooddratd">32.07%</td><td class="oodtratd">27.89%</td><td class="oodratd">29.98%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-20</td><td class="venuetd">ICML 2020</td></tr>
<tr><td class="ranktd">57</td><td class="methoddt"><a href="https://arxiv.org/abs/2011.11164" target="_blank">Learnable Boundary Guided Adversarial Training</a><br><span class="td-footer">Uses \(\ell_{\infty} \) = 0.031 ≈ 7.9/255 instead of 8/255</span></td><td class="idcatd">88.70%</td><td class="idratd">53.33%</td><td class="ooddcatd">70.60%</td><td class="ooddratd">32.00%</td><td class="oodtratd">26.49%</td><td class="oodratd">29.25%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-20</td><td class="venuetd">ICCV 2021</td></tr>
<tr><td class="ranktd">58</td><td class="methoddt"><a href="https://arxiv.org/abs/2010.01278" target="_blank">Efficient Robust Training via Backward Smoothing</a></td><td class="idcatd">85.32%</td><td class="idratd">51.43%</td><td class="ooddcatd">67.06%</td><td class="ooddratd">31.36%</td><td class="oodtratd">27.00%</td><td class="oodratd">29.18%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">arXiv, Oct 2020</td></tr>
<tr><td class="ranktd">59</td><td class="methoddt"><a href="https://arxiv.org/abs/1901.08573" target="_blank">Theoretically Principled Trade-off between Robustness and Accuracy</a><br><span class="td-footer">Uses \(\ell_{\infty} \) = 0.031 ≈ 7.9/255 instead of 8/255.</span></td><td class="idcatd">84.92%</td><td class="idratd">52.68%</td><td class="ooddcatd">66.51%</td><td class="ooddratd">31.68%</td><td class="oodtratd">26.54%</td><td class="oodratd">29.11%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">ICML 2019</td></tr>
<tr><td class="ranktd">60</td><td class="methoddt"><a href="https://arxiv.org/abs/2011.11164" target="_blank">Learnable Boundary Guided Adversarial Training</a><br><span class="td-footer">Uses \(\ell_{\infty} \) = 0.031 ≈ 7.9/255 instead of 8/255</span></td><td class="idcatd">88.22%</td><td class="idratd">52.60%</td><td class="ooddcatd">69.95%</td><td class="ooddratd">31.02%</td><td class="oodtratd">25.95%</td><td class="oodratd">28.49%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">ICCV 2021</td></tr>
<tr><td class="ranktd">61</td><td class="methoddt"><a href="https://arxiv.org/abs/2003.09347" target="_blank">Improving Adversarial Robustness Through Progressive Hardening</a></td><td class="idcatd">86.84%</td><td class="idratd">50.91%</td><td class="ooddcatd">68.85%</td><td class="ooddratd">30.49%</td><td class="oodtratd">24.98%</td><td class="oodratd">27.74%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">arXiv, Mar 2020</td></tr>
<tr><td class="ranktd">62</td><td class="methoddt"><a href="https://github.com/MadryLab/robustness" target="_blank">Robustness library</a></td><td class="idcatd">87.03%</td><td class="idratd">49.66%</td><td class="ooddcatd">70.24%</td><td class="ooddratd">29.65%</td><td class="oodtratd">25.05%</td><td class="oodratd">27.35%</td><td class="datatd">&#215;</td><td class="archtd">ResNet-50</td><td class="venuetd">GitHub,<br>Oct 2019</td></tr>
<tr><td class="ranktd">63</td><td class="methoddt"><a href="https://arxiv.org/abs/2007.02617" target="_blank">Understanding and Improving Fast Adversarial Training</a><br><span class="td-footer">Focuses on fast adversarial training.</span></td><td class="idcatd">79.84%</td><td class="idratd">44.17%</td><td class="ooddcatd">62.43%</td><td class="ooddratd">26.79%</td><td class="oodtratd">26.62%</td><td class="oodratd">26.70%</td><td class="datatd">&#215;</td><td class="archtd">PreActResNet-18</td><td class="venuetd">NeurIPS 2020</td></tr>
<tr><td class="ranktd">64</td><td class="methoddt"><a href="https://arxiv.org/abs/2001.03994" target="_blank">Fast is better than free: Revisiting adversarial training</a><br><span class="td-footer">Focuses on fast adversarial training.</span></td><td class="idcatd">83.34%</td><td class="idratd">43.33%</td><td class="ooddcatd">64.96%</td><td class="ooddratd">25.35%</td><td class="oodtratd">24.82%</td><td class="oodratd">25.08%</td><td class="datatd">&#215;</td><td class="archtd">PreActResNet-18</td><td class="venuetd">ICLR 2020</td></tr>
<tr><td class="ranktd">65</td><td class="methoddt"><a href="https://arxiv.org/abs/1905.00877" target="_blank">You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle</a><br><span class="td-footer">Focuses on fast adversarial training.</span></td><td class="idcatd">87.20%</td><td class="idratd">45.05%</td><td class="ooddcatd">68.94%</td><td class="ooddratd">25.58%</td><td class="oodtratd">22.86%</td><td class="oodratd">24.22%</td><td class="datatd">&#215;</td><td class="archtd">WideResNet-34-10</td><td class="venuetd">NeurIPS 2019</td></tr>
      
    </tbody>
</table>
<script>
    $(document).ready(function () {
        $("#cifar10_leaderboard_Linf").DataTable({
            lengthMenu: [15, 25, 50, 75, 100],
            "drawCallback": function (settings) {
                MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
            },
            language: {
                searchPlaceholder: "Papers, architectures, venues"
            },
            
            columnDefs: [
                { width: "15%", targets: 4 },
                { width: "15%", targets: 5 }
            ]
            
        });
    });
</script>
